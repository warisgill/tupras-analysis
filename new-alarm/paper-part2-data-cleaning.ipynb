{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepared Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alarms2 import *\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def findChatteringsv2(alarms, chattering_timedelta_threshold=60.0, chattering_count_threshold=3):\n",
    "#     \"\"\"Find the chatterings in an alarms list from the same source. \n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     alarms  : list of dict\n",
    "#         A list of alarms from the same source. \n",
    "#     chattering_timedelta_threshold : float, optional\n",
    "#         Duration in seconds for which to finde cattering alarms, by default 60.0 seconds.\n",
    "#     chattering_count_threshold : int, optional\n",
    "#         Threshold for minimum number of alarms to be activated in duration of chattering_timedelta_threshold, by default 3\n",
    "\n",
    "#     Returns\n",
    "#     ----------\n",
    "#     chattering : dict\n",
    "#         It contains the StartTime as key of chattering, and a dict as a value which is \n",
    "#         consits of an index and a count of of alarms chattered within chattering_timedelta_threshold next \n",
    "#         to it.  \n",
    "#     \"\"\"\n",
    "#     alarms_without_chatters = []\n",
    "#     chattering = {}\n",
    "#     alarms = [alarm for alarm in sorted(alarms, key=lambda arg: arg[\"StartTime\"], reverse=False)]\n",
    "#     i = 0\n",
    "#     j = 0\n",
    "\n",
    "#     while i < (len(alarms)):\n",
    "#         prev_start = alarms[i][\"StartTime\"]\n",
    "#         prev_end = alarms[i][\"EndTime\"]\n",
    "#         count_alarms = 0\n",
    "#         j = i + 1\n",
    "#         while j < len(alarms):\n",
    "#             next_start = alarms[j][\"StartTime\"]\n",
    "#             next_end = alarms[j][\"EndTime\"]\n",
    "\n",
    "#             # this assert is very important: the prev alarm has to turn off before the start of\n",
    "#             # the next one\n",
    "#             if prev_end > next_start:\n",
    "#                 print(alarms[i][\"SourceName\"], alarms[j][\"SourceName\"])\n",
    "#                 print(prev_start,prev_end, next_start,next_end)\n",
    "#             assert(prev_start <= next_start)\n",
    "#             assert(prev_end <= next_start)\n",
    "#             assert(prev_end <= next_end)\n",
    "\n",
    "#             delta = timedelta.total_seconds(next_start - prev_start)\n",
    "#             assert (delta >= 0)\n",
    "#             if delta > chattering_timedelta_threshold:\n",
    "#                 break\n",
    "#             count_alarms += 1\n",
    "# #             print(time_delta, \"count ++ \", count, t_prev, t_next)\n",
    "#             j += 1\n",
    "\n",
    "#         alarms_without_chatters.append(alarms[i])\n",
    "#         if count_alarms >= chattering_count_threshold:\n",
    "#             chattering[prev_start] = {\"index\": i, \"count\": count_alarms}\n",
    "#             i = j\n",
    "#         else:\n",
    "#             i += 1\n",
    "        \n",
    "\n",
    "#     return chattering, alarms_without_chatters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/new/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarms_fname = \"formatted-all-month-alarms.csv\" \n",
    "# operator_fname = \"operator-all-month-actions.csv\"\n",
    "\n",
    "df_main_alarms = pd.read_csv(path + alarms_fname, low_memory=False ,parse_dates=[\"StartTime\", \"EndTime\"])\n",
    "df_main_alarms[\"TimeDelta\"] = df_main_alarms[\"EndTime\"] - df_main_alarms[\"StartTime\"]\n",
    "df_main_alarms[\"TimeDelta\"] = df_main_alarms[\"TimeDelta\"].apply(lambda arg: timedelta.total_seconds(arg)) \n",
    "df_main_alarms[\"Month\"] = df_main_alarms[\"StartTime\"].apply(lambda arg: arg.month)\n",
    "\n",
    "# df_main_actions = pd.read_csv(path + operator_fname, low_memory=False ,parse_dates=[\"EventTime\"])\n",
    "# df_main_actions[\"Month\"] = df_main_actions[\"EventTime\"].apply(lambda arg: arg.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Some Uncessary Alarms From Orignal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "169\n169\n{'47TI931A': 58368, '47TI1713': 16954, '47PI1734': 10973, '48PI2025': 10563, '47LIC005': 3636, '47FI1575': 3004, '48FIX2040': 2627, '48TIC2027': 2627, '47PIC1755': 2486, '47PDI1746': 2403, '47FI1568': 2281, '48XL001-ANN': 2118, '47FLI-039': 1962, 'SIO-18XA001': 1947, '19LI105A': 1939, '48XL002-ANN': 1851, '47PDI1747': 1658, '47TI003B': 1394, '47LI003': 1317, '47TI003A': 1078, '47LIC1503': 1033, '47TIC3520': 967, '47TI002C': 941, '19G402-ANN': 923, '19XL101-ANN': 923, '47PDI003': 740, '47PIC2033A': 727, '47PI2029C': 717, '47PIC1505': 701, '48TIC034': 698, '47PI2039B': 688, '47PI2039A': 668, '47FLI-042': 652, '47FI043': 647, '47XL015-ANN': 640, '47XL016-ANN': 633, '47PI2039C': 629, '47PI2029B': 604, '47TAL003AB-ANN': 595, '47PI2029A': 595, '48FI2003A': 562, '47TI1769': 552, '47TI1512A': 509, '47PDIC1759': 465, '47TI1512B': 459, '47TI1512ABC': 436, '47TI1723': 428, '47TI1512C': 402, '48LI015': 399, '47FLI-037': 354, '47FI1005': 353, '47PIC2064': 325, '47LIC3103': 320, '47HCI-003': 308, '48FFIC2002': 303, '47PIC3522': 299, '48FALL2003-ANN': 291, '47LIC1509': 284, '47AI2003': 263, '47TI3519': 250, '47LIC3408': 250, '48LI011': 243, '47LIC1506': 232, '47LIC009': 232, '47LIC1518': 229, '48XL010-ANN': 226, '48XL009-ANN': 226, '47LIC1501': 225, '47FI1509': 208, '47PIC027-ANN': 202, '48LI013': 193, '47TI1506': 187, '47FLI-036': 176, '47TI2112A': 175, '47FI2030': 155, '47TI2077': 155, '47PDAH605-ANN': 152, '47TI2111A': 148, '47LIC1505': 147, '47TI870D': 137, '47FI1502C': 133, '47LIC002': 131, '47LIC3409': 130, '47TI416': 127, '47TI3531': 127, '47PI1519': 126, '47FIC3513': 126, '47TI1533': 126, '47LI024': 124, '47AIT2014': 123, '48LI010': 123, '47TI870A': 122, '47LIC1551': 119, '47PI1710': 117, '47FI1505B': 113, '47FI1571': 112, '47LIC1522': 111, '47PI2064': 111, '48XL012-ANN': 106, '19FI108A': 106, '47TI1521': 104, '47FSL019-ANN': 102, '47LIC3510': 102, '47TI1705': 101, '47FI1502D': 101, '47TXI1594': 100, '47TXI1592': 98, '47TI2111B': 92, '47TIC1535': 92, '19PI119A': 91, '47PDI1749': 91, '48XL006-ANN': 90, '47TIC2078': 90, '47FIC1515': 90, '47FIC037': 88, '47FI1502B': 87, '48XL005-ANN': 86, '48LIC2003': 86, '47PIC027': 83, '47TI1540': 82, '47TI2112B': 82, '47FD-032H-ANN': 81, '47FD-032HH-ANN': 81, '47_AMPSA_PMCC1L': 79, '47TAH808-ANN': 77, '47LIC1513': 77, '47PI1003': 77, '47XL1001-ANN': 77, '47TI2086': 74, '47TIC1501': 74, '48FI2021B': 72, '47PDI3104': 71, '48LIC009': 70, '48FI2021A': 69, '47TIC2056': 69, '47G12-A': 68, '47FIC1563': 68, '47FI1504C': 68, '47PIC2023': 67, '47LIC1511': 67, '47LI606A': 66, '47FI1505D': 64, '47FIC1505': 63, '47FIC1523': 63, '47FIC1507': 63, '47FD-036H-ANN': 61, '47PIC3522-ANN': 61, '19LIC104': 61, '47PIC2028': 61, '47FD-036HH-ANN': 60, '47FIC1520': 60, '47AIC003': 60, '47_AMPSC_PMCC1L': 60, '19TI104': 60, '47FIC1504': 59, '47TI414Q': 58, '47TI1507': 58, '48BAL007-ANN': 58, '47PIC1504': 57, '47TI1508': 56, '48UA007-ANN': 56, '47FIC1502': 54, '47LIC1502': 53, '47FIC1522A': 52, '48TI003A': 52, '47FIC034': 51, '19ZAL119A-ANN': 50, '47FI1504D': 50, '47PIC2038': 50}\n"
    }
   ],
   "source": [
    "filter_short_alarms = [20]\n",
    "min_alarms_per_source = 50 # include only these alarms\n",
    "igonre_snames = [] # \"47TI1713\" ignore these alarms\n",
    "\n",
    "# df_temp = df_main_alarms\n",
    "df_f2 = df_main_alarms[df_main_alarms[\"TimeDelta\"]>filter_short_alarms[0]]\n",
    "len( df_main_alarms[\"SourceName\"].unique()),len(df_f2[\"SourceName\"].unique())\n",
    "\n",
    "source2count = dict(df_f2[\"SourceName\"].value_counts())\n",
    "source2count = {k:v for k,v in source2count.items() if v>=min_alarms_per_source}\n",
    "\n",
    "print(len(source2count))\n",
    "\n",
    "df_rnn = df_main_alarms[(df_main_alarms[\"TimeDelta\"]>=filter_short_alarms[0]) & (df_main_alarms[\"SourceName\"].isin(source2count.keys())) & (~df_main_alarms[\"SourceName\"].isin(igonre_snames))]\n",
    "\n",
    "source2count = dict(df_rnn[\"SourceName\"].value_counts())\n",
    "source2count = {k:v for k,v in source2count.items() if v>=min_alarms_per_source}\n",
    "print(len(source2count))\n",
    "print(source2count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " df_rnn = df_rnn[df_rnn[\"SourceName\"].isin(source2count.keys())]\n",
    "#  for sname in df_rnn[\"SourceName\"].unique():\n",
    "#     print(\">>\",sname)\n",
    "#     df_sname = df_rnn[df_rnn[\"SourceName\"]==sname]\n",
    "#     for condition in df_sname[\"Condition\"].unique():\n",
    "#         df_condition = df_sname[df_sname[\"Condition\"]==condition]\n",
    "#         chats, without_chatter = findChatteringsv2(df_condition.to_dict(orient=\"records\"))\n",
    "#         print(len(chats),len(without_chatter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to preprocess the data\n",
    "\n",
    " Removing short sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "def getSequenceByMonth(df,month,seq_duration_gap,filter_short_seq,filter_long_seq):\n",
    "    print(f\">> Seq By Month:{month}, duration to next seq: {seq_duration_gap}, ignore seq len: {filter_short_seq}\")\n",
    "\n",
    "    list_of_sequences = []\n",
    "    max_len = 0\n",
    "    min_len = 9999   \n",
    "    df_month = df[df[\"Month\"]==month]\n",
    "    assert 1 == len(df_month[\"Month\"].unique())\n",
    "    \n",
    "    alarms= df_month.to_dict(orient=\"records\")\n",
    "    alarms = [alarm for alarm in sorted(alarms, key=lambda arg: arg[\"StartTime\"], reverse=False)] # sorting\n",
    "    # print(alarms[:2])\n",
    "    i =0\n",
    "    j= 0\n",
    "    while i <len(alarms):\n",
    "        prev_start = alarms[i][\"StartTime\"]\n",
    "        seq = []\n",
    "        seq.append(alarms[i])\n",
    "        j = i+1\n",
    "        while j < len(alarms):    \n",
    "            next_start = alarms[j][\"StartTime\"]\n",
    "            delta = timedelta.total_seconds(next_start - prev_start)\n",
    "            # print(delta)\n",
    "            assert delta >= 0\n",
    "            if delta >= seq_duration_gap:\n",
    "                break\n",
    "            if len(seq) > filter_long_seq:\n",
    "                # seq = [alarm for alarm in sorted(seq, key=lambda arg: arg[\"StartTime\"], reverse=False)]\n",
    "                # seq = [alarm[\"SourceName\"] for alarm in seq]\n",
    "                # list_of_sequences.append(seq)\n",
    "                # print(\"<<\",len(seq))\n",
    "                break\n",
    "\n",
    "            seq.append(alarms[j])\n",
    "            j += 1\n",
    "        i = j\n",
    "        if len(seq)>max_len:\n",
    "            max_len = len(seq)\n",
    "        if len(seq)<min_len:\n",
    "            min_len = len(seq)\n",
    "        \n",
    "\n",
    "        if len(seq)>=filter_short_seq:\n",
    "            seq = [alarm for alarm in sorted(seq, key=lambda arg: arg[\"StartTime\"], reverse=False)]\n",
    "            seq = [alarm[\"SourceName\"] for alarm in seq]\n",
    "            list_of_sequences.append(seq)\n",
    "    \n",
    "    # list_of_sequences = [l for l in list_of_sequences if (len(l)>filter_short_alarms)]\n",
    "    print(f\">> Min Seq Len: {min_len}, max seq len: {max_len}\")\n",
    "    return list_of_sequences\n",
    "\n",
    "\n",
    "#Doing Padding\n",
    "def padding(seq_length,arr):\n",
    "    \n",
    "    if len(arr) < seq_length:\n",
    "        return [\"NoName\" for i in range(seq_length-len(arr))] + arr\n",
    "    elif len(arr) > seq_length: # if bigger than seq_length use earliers\n",
    "        return arr[0:seq_length]\n",
    "\n",
    "    return arr\n",
    "\n",
    "def getAllMonths2Seqs(df,seq_length,seq_time_gap,seq_ignore_len,filter_long_seq):\n",
    "    print(f\">> All Months: Seq_len = {seq_length}\")\n",
    "    month2alarms = {}\n",
    "\n",
    "    for month in df[\"Month\"].unique():\n",
    "        li_of_seqs = getSequenceByMonth(df,month,seq_time_gap,seq_ignore_len,filter_long_seq) \n",
    "        f = partial(padding,seq_length)\n",
    "        month2alarms[month] = [f(l) for l in li_of_seqs]\n",
    "    \n",
    "    return month2alarms\n",
    "\n",
    "\n",
    "def getTrainAndValidationData(df,seq_length,seq_time_gap,seq_ignore_len,filter_long_seq,test_size,shuffle=False):\n",
    "    print(f\">> Spliting Data Size (valid%): {test_size}\")\n",
    "    train_data = []\n",
    "    valid_data = []\n",
    "    months2seq = getAllMonths2Seqs(df,seq_length=seq_length,seq_time_gap=seq_time_gap,seq_ignore_len=seq_ignore_len,filter_long_seq=filter_long_seq)\n",
    "\n",
    "    for month in df[\"Month\"].unique():\n",
    "      train,valid = train_test_split(months2seq[month],test_size=test_size,shuffle=shuffle)\n",
    "      train_data += train\n",
    "      valid_data += valid\n",
    "\n",
    "    return train_data, valid_data  \n",
    "\n",
    "def encodeData(mydict,l):\n",
    "    return [mydict[e] for e in l]\n",
    "\n",
    "def getInputsAndTargets(encoded_alarms):\n",
    "    input_seqs_train = []\n",
    "    target_seqs_train = []\n",
    "\n",
    "    for i in range(len(encoded_alarms)):\n",
    "        # remove the last char from input seq\n",
    "        input_seqs_train.append(encoded_alarms[i][:-1])\n",
    "\n",
    "        # remove the first char from input seq\n",
    "        target_seqs_train.append(encoded_alarms[i][1:])\n",
    "        # print(f\"orignal={encoded_alarms[i]} \\n Input Seq={input_seqs_train[i]}, \\n Target Seq = {target_seqs_train[i]}\")\n",
    "\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for l in input_seqs_train:\n",
    "        inputs = inputs+l\n",
    "\n",
    "    for l in target_seqs_train:\n",
    "        targets = targets + l\n",
    "\n",
    "\n",
    "    # for row in range(len(input_seqs_train)): \n",
    "    row = 0\n",
    "\n",
    "    # print(inputs[row*(seq_length-1):row*(seq_length-1)+ seq_length-1],targets[row*(seq_length-1):row*(seq_length-1)+ seq_length-1])\n",
    "    print(input_seqs_train[row], target_seqs_train[row])\n",
    "    return inputs, targets, input_seqs_train, target_seqs_train\n",
    "\n",
    "def one_hot_encode(arr, n_labels):\n",
    "    \n",
    "    # Initialize the the encoded array\n",
    "    # print(arr.size) # total number of memory locations \n",
    "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
    "    \n",
    "    # Fill the appropriate elements with ones\n",
    "    indexes = np.arange(one_hot.shape[0]), arr.flatten()\n",
    "    # print(indexes)\n",
    "    one_hot[indexes] = 1.\n",
    "    \n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "def get_batches(arr1,arr2, batch_size, seq_length):\n",
    "    '''Create a generator that returns batches of size\n",
    "       batch_size x seq_length from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       batch_size: Batch size, the number of sequences per batch\n",
    "       seq_length: Number of encoded chars in a sequence\n",
    "    '''\n",
    "    \n",
    "    ## TODO: Get the number of batches we can make\n",
    "    t = arr1.size//(batch_size * seq_length)\n",
    "    \n",
    "    n_batches =  t\n",
    "    \n",
    "    ## TODO: Keep only enough characters to make full batches\n",
    "    arr1 =  arr1[:batch_size*(seq_length*n_batches)]\n",
    "    arr2 =  arr2[:batch_size*(seq_length*n_batches)]\n",
    "\n",
    "    ## TODO: Reshape into batch_size rows\n",
    "    arr1 = arr1.reshape((batch_size,-1))\n",
    "    arr2 = arr2.reshape((batch_size,-1))\n",
    "    \n",
    "    ## TODO: Iterate over the batches using a window of size seq_length\n",
    "    for n in range(0, arr1.shape[1], seq_length):\n",
    "        # The features\n",
    "        x = arr1[:,n:n+seq_length]\n",
    "        y = arr2[:,n:n+seq_length]\n",
    "        \n",
    "        \n",
    "        yield x, y\n",
    "    \n",
    "\n",
    "# sequences = getSequenceByMonth(df_rnn,3)\n",
    "# # sequences \n",
    "\n",
    "# print(len(sequences))\n",
    "# print(max([len(seq) for seq in sequences]),min([len(seq) for seq in sequences]))\n",
    "# # print([len(seq) for seq in sequences])\n",
    "# print(sequences[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mention the Sequence Length => how many alarms you want to put in a sequence\n",
    "Any change need to rerun from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "===== Without Ignoring Short Seq==========\n>> Spliting Data Size (valid%): 0.2\n>> All Months: Seq_len = 5\n>> Seq By Month:3, duration to next seq: 600, ignore seq len: 0\n>> Min Seq Len: 1, max seq len: 6\n>> Seq By Month:4, duration to next seq: 600, ignore seq len: 0\n>> Min Seq Len: 1, max seq len: 6\n>> Seq By Month:5, duration to next seq: 600, ignore seq len: 0\n>> Min Seq Len: 1, max seq len: 6\n>> Seq By Month:6, duration to next seq: 600, ignore seq len: 0\n>> Min Seq Len: 2, max seq len: 6\n>> Train Size: 22256, Validation Size: 5567\n      ===== Ignoring Short Seq==========\n>> Spliting Data Size (valid%): 0.2\n>> All Months: Seq_len = 5\n>> Seq By Month:3, duration to next seq: 600, ignore seq len: 4\n>> Min Seq Len: 1, max seq len: 6\n>> Seq By Month:4, duration to next seq: 600, ignore seq len: 4\n>> Min Seq Len: 1, max seq len: 6\n>> Seq By Month:5, duration to next seq: 600, ignore seq len: 4\n>> Min Seq Len: 1, max seq len: 6\n>> Seq By Month:6, duration to next seq: 600, ignore seq len: 4\n>> Min Seq Len: 2, max seq len: 6\n>> Train Size: 22060, Validation Size: 5518\n['47PDI1749', '47PI1734', '47PI1734', '47PI1734', '47PI1734']\n"
    }
   ],
   "source": [
    "seq_length = 5\n",
    "ingore_short_seq_len = 4\n",
    "long_len = seq_length \n",
    "duration_from_1_seq_to_next = 60*10 # duration in seconds\n",
    "test_size = 0.2\n",
    "shuffle = False\n",
    "\n",
    "print(\"    ===== Without Ignoring Short Seq==========\") \n",
    "train_data, valid_data = getTrainAndValidationData(df_rnn,seq_length=seq_length,seq_time_gap=duration_from_1_seq_to_next,seq_ignore_len=0,filter_long_seq=long_len,test_size=test_size,shuffle=shuffle)\n",
    "\n",
    "print(f\">> Train Size: {len(train_data)}, Validation Size: {len(valid_data)}\")  \n",
    "\n",
    "\n",
    "print(\"      ===== Ignoring Short Seq==========\") \n",
    "train_data, valid_data = getTrainAndValidationData(df_rnn,seq_length=seq_length,seq_time_gap=duration_from_1_seq_to_next,seq_ignore_len=ingore_short_seq_len, filter_long_seq=long_len,test_size=test_size,shuffle=shuffle)\n",
    "\n",
    "print(f\">> Train Size: {len(train_data)}, Validation Size: {len(valid_data)}\")  \n",
    "print(valid_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Vocab and conversion from vocab2int and into2vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(22060, 5)"
     },
     "metadata": {},
     "execution_count": 259
    }
   ],
   "source": [
    "\n",
    "vocab = set(list(itertools.chain.from_iterable(train_data+valid_data)))\n",
    "int2vocab = dict(enumerate(vocab))\n",
    "vocab2int = {v:k for k,v in int2vocab.items()}\n",
    "assert len(vocab2int) == len(vocab)\n",
    "\n",
    "f = partial(encodeData,vocab2int)\n",
    "encoded_train_alarms = [f(l) for l in train_data]\n",
    "encoded_valid_alarms = [f(l) for l in valid_data]\n",
    "\n",
    "\n",
    "train_features = np.array(encoded_train_alarms)\n",
    "train_features.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data To Use mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ">> ============ Training Set ==============\n[16, 16, 16, 152] [16, 16, 152, 89]\n[16, 16, 16, 152] [16, 16, 152, 89]\n>> =========== Validation Set ==============\n[16, 141, 113, 144] [141, 113, 144, 113]\n[16, 141, 113, 144] [141, 113, 144, 113]\n>> Ignore Seq 147\n"
    }
   ],
   "source": [
    "\n",
    "row = 0 # this row should always be zero because in function it is zero\n",
    "\n",
    "print(\">> ============ Training Set ==============\")\n",
    "train_inputs, train_targets, _, _ = getInputsAndTargets(encoded_train_alarms)\n",
    "print(train_inputs[row*(seq_length-1):row*(seq_length-1)+ seq_length-1],train_targets[row*(seq_length-1):row*(seq_length-1)+ seq_length-1])\n",
    "\n",
    "print(\">> =========== Validation Set ==============\")\n",
    "valid_inputs, valid_targets, _, _ = getInputsAndTargets(encoded_valid_alarms)    \n",
    "print(valid_inputs[row*(seq_length-1):row*(seq_length-1)+ seq_length-1],valid_targets[row*(seq_length-1):row*(seq_length-1)+ seq_length-1])\n",
    "\n",
    "print(\">> Ignore Seq\", vocab2int[\"NoName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Mini Batches\n",
    "\n",
    "Below output should be similar to above 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2, 4) (2, 4)\nx\n [[ 16  16  16 152]\n [ 42  16  16 137]]\n\ny\n [[ 16  16 152  89]\n [ 16  16 137  16]]\n"
    }
   ],
   "source": [
    "batches = get_batches(np.array(train_inputs),np.array(train_targets),batch_size=2, seq_length=seq_length-1)\n",
    "x, y = next(batches)\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "# printing out the first 10 items in a sequence\n",
    "print('x\\n', x)\n",
    "print('\\ny\\n', y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training on GPU!\n"
    }
   ],
   "source": [
    "# check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlarmRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,tokens,int2vocab,vocab2int, n_hidden=256, n_layers=2,\n",
    "                               drop_prob=0.5, lr=0.001):\n",
    "        super(AlarmRNN,self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        # creating character dictionaries\n",
    "        self.chars = tokens # vocab\n",
    "        # int2vocab = dict(enumerate(self.chars))\n",
    "        # vocab2int = {v:k for k,v in int2vocab.items()}\n",
    "\n",
    "        self.int2char = int2vocab #dict(enumerate(self.chars))\n",
    "        self.char2int = vocab2int  #{ch: ii for ii, ch in self.int2char.items()}\n",
    "                \n",
    "        ## TODO: define the layers of the model\n",
    "        self.lstm = nn.LSTM(input_size=len(self.chars), hidden_size=self.n_hidden, num_layers=self.n_layers,dropout=self.drop_prob, batch_first=True)\n",
    "        self.droput = nn.Dropout(p=self.drop_prob)\n",
    "        self.fc = nn.Linear(in_features=self.n_hidden, out_features=len(self.chars))   \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "                \n",
    "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
    "        out, hidden = self.lstm(x,hidden)\n",
    "        out = self.droput(out)\n",
    "        # Contiguous variables: If you are stacking up multiple LSTM outputs, it may be necessary to use .contiguous() to reshape the output.\n",
    "        out = out.contiguous().view(-1,self.n_hidden)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,data,seq_length,batch_size,epochs=10, lr=0.001, clip=5, print_every=10):\n",
    "    ''' Training a network \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        net: CharRNN network\n",
    "        data: text data to train the network\n",
    "        epochs: Number of epochs to train\n",
    "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
    "        seq_length: Number of character steps per mini-batch\n",
    "        lr: learning rate\n",
    "        clip: gradient clipping\n",
    "        val_frac: Fraction of data to hold out for validation\n",
    "        print_every: Number of steps for printing training and validation loss\n",
    "    \n",
    "    '''\n",
    "    print(f\"Batch Size ={batch_size}, seq_length={seq_length}\")\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # create training and validation data\n",
    "    # val_idx = int(len(data)*(1-val_frac))\n",
    "    # data, val_data = data[:val_idx], data[val_idx:]\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    \n",
    "    counter = 0\n",
    "    n_chars = len(net.chars)\n",
    "    loss = 0\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        h = net.init_hidden(batch_size)\n",
    "        \n",
    "        for x, y in get_batches(data[\"train_inputs\"], data[\"train_targets\"], batch_size, seq_length):\n",
    "            counter += 1\n",
    "            \n",
    "            # One-hot encode our data and make them Torch tensors\n",
    "            x = one_hot_encode(x, n_chars)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            if(train_on_gpu):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = net(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "            \n",
    "        # loss stats with validation \n",
    "        if (e+1) % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for x, y in get_batches(data[\"valid_inputs\"],data[\"valid_targets\"],batch_size, seq_length):\n",
    "                # One-hot encode our data and make them Torch tensors\n",
    "                x = one_hot_encode(x, n_chars)\n",
    "                x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                \n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                \n",
    "                inputs, targets = x, y\n",
    "                if(train_on_gpu):\n",
    "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
    "            \n",
    "                val_losses.append(val_loss.item())\n",
    "            \n",
    "            net.train() # reset to train mode after iterationg through validation data\n",
    "            \n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                    \"Step: {}...\".format(counter),\n",
    "                    \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                    \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(net, char, h=None, top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "            Returns the predicted character and the hidden state.\n",
    "        '''\n",
    "        if(train_on_gpu):\n",
    "            net.cuda()\n",
    "        else:\n",
    "            net.cpu()\n",
    "\n",
    "        net.eval() # I have written this\n",
    "\n",
    "        # tensor inputs\n",
    "        x = np.array([[net.char2int[char]]])\n",
    "        x = one_hot_encode(x, len(net.chars))\n",
    "        inputs = torch.from_numpy(x)\n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        # detach hidden state from history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # get the output of the model\n",
    "        out, h = net(inputs, h)\n",
    "\n",
    "        # get the character probabilities\n",
    "        p = F.softmax(out, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "        \n",
    "        # get top characters\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(net.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        # select the likely next character with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        \n",
    "        # return the encoded value of the predicted char and the hidden state\n",
    "        return net.int2char[char], h\n",
    "\n",
    "def sample(net,h,input_sequence,prime,top_k=None):\n",
    "    # print(f\">>Prime:{prime}, Input Seq: {input_sequence}\")\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.cpu()\n",
    "    \n",
    "    net.eval() # eval mode\n",
    "    \n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    char = None\n",
    "    for ch in prime:\n",
    "        char, h = predict(net, ch, h, top_k=top_k)\n",
    "\n",
    "    output = None\n",
    "    for ch in input_sequence:\n",
    "        # print(\">> \", ch)\n",
    "        # if ch == \"NoName\":\n",
    "        #     continue\n",
    "        output, h = predict(net, ch, h, top_k=top_k)\n",
    "    \n",
    "    \n",
    "    return output,h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(inputs,targets,net):\n",
    "    correct = 0\n",
    "    wrong = 0 \n",
    "    hidden = net.init_hidden(1)\n",
    "    prime = ['19LI105A', '47TI931A', '48XL001-ANN', '19LI105A', '47TI931A']\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        # output,hidden =sample(net,hidden,input_sequence=inputs[i], prime=prime, top_k=None)\n",
    "        for j in  range(len(inputs[0])):\n",
    "            output,hidden =predict(net,char= inputs[i][j], h=hidden,top_k=None)\n",
    "            \n",
    "            target = targets[i][j]\n",
    "            # print(\">> output\", output)\n",
    "            # print(\">> Target\", target)\n",
    "            if output == target and target != \"NoName\":\n",
    "                correct += 1\n",
    "            elif output != target and target != \"NoName\":\n",
    "                wrong += 1\n",
    "\n",
    "    accuracy = correct/(wrong+correct)\n",
    "    return accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['47TI931A', '47TI931A', '47TI931A', '48FIX2040'] ['47TI931A', '47TI931A', '48FIX2040', '48TIC2027']\n['47TI931A', '47PDI1747', '47PI1734', '47LIC3103'] ['47PDI1747', '47PI1734', '47LIC3103', '47PI1734']\n"
    }
   ],
   "source": [
    "_,_,myinputs_t, mytargets_t = getInputsAndTargets(train_data)\n",
    "train_aacuracy_fun = partial(getAccuracy, myinputs_t, mytargets_t) \n",
    "\n",
    "_,_,myinputs_v, mytargets_v = getInputsAndTargets(valid_data)\n",
    "validation_aacuracy_fun = partial(getAccuracy, myinputs_v, mytargets_v) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AlarmRNN(\n  (lstm): LSTM(170, 256, num_layers=2, batch_first=True)\n  (droput): Dropout(p=0.0, inplace=False)\n  (fc): Linear(in_features=256, out_features=170, bias=True)\n)\nBatch Size =1024, seq_length=4\nEpoch: 10/200... Step: 210... Loss: 2.9479... Val Loss: 2.9784\nEpoch: 20/200... Step: 420... Loss: 2.5433... Val Loss: 2.5605\nEpoch: 30/200... Step: 630... Loss: 2.2749... Val Loss: 2.3960\nEpoch: 40/200... Step: 840... Loss: 2.1275... Val Loss: 2.2727\nEpoch: 50/200... Step: 1050... Loss: 2.0456... Val Loss: 2.2872\nEpoch: 60/200... Step: 1260... Loss: 1.9758... Val Loss: 2.3073\nEpoch: 70/200... Step: 1470... Loss: 1.8270... Val Loss: 2.3549\nEpoch: 80/200... Step: 1680... Loss: 1.7371... Val Loss: 2.4334\nEpoch: 90/200... Step: 1890... Loss: 1.5995... Val Loss: 2.5289\nEpoch: 100/200... Step: 2100... Loss: 1.4340... Val Loss: 2.6431\nEpoch: 110/200... Step: 2310... Loss: 1.3365... Val Loss: 2.8233\nEpoch: 120/200... Step: 2520... Loss: 1.1814... Val Loss: 2.8749\nEpoch: 130/200... Step: 2730... Loss: 1.0436... Val Loss: 3.0236\nEpoch: 140/200... Step: 2940... Loss: 0.9547... Val Loss: 3.1749\nEpoch: 150/200... Step: 3150... Loss: 0.8690... Val Loss: 3.3637\nEpoch: 160/200... Step: 3360... Loss: 0.7657... Val Loss: 3.4749\nEpoch: 170/200... Step: 3570... Loss: 0.7023... Val Loss: 3.5941\nEpoch: 180/200... Step: 3780... Loss: 0.6463... Val Loss: 3.7141\nEpoch: 190/200... Step: 3990... Loss: 0.5396... Val Loss: 3.8803\nEpoch: 200/200... Step: 4200... Loss: 0.4765... Val Loss: 3.9738\nAccuracy: Train =  0, valid = 0, 0 means intentally is set to zero\n"
    }
   ],
   "source": [
    "## TODO: set your model hyperparameters\n",
    "# define and print the net\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "n_hidden=256\n",
    "n_layers=2\n",
    "n_epochs = 200 # start small if you are just testing initial behavior\n",
    "batch_size = 1024\n",
    "data = {\"train_inputs\":np.array(train_inputs), \"train_targets\": np.array(train_targets), \"valid_inputs\":np.array(valid_inputs), \"valid_targets\":np.array(valid_targets)}\n",
    "\n",
    "net = AlarmRNN(vocab,int2vocab,vocab2int,n_hidden, n_layers,drop_prob=0.0)\n",
    "print(net)\n",
    "\n",
    "# train the model\n",
    "train(net,data, seq_length=seq_length-1, batch_size=batch_size, epochs=n_epochs,lr=0.002, print_every=10)\n",
    "\n",
    "train_accuracy = 0\n",
    "valid_accuracy = 0\n",
    "# train_accuracy = train_aacuracy_fun(net)\n",
    "# valid_accuracy = validation_aacuracy_fun(net)\n",
    "print(f\"Accuracy: Train =  {train_accuracy}, valid = {valid_accuracy}, 0 means intentally is set to zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: Train =  65.74682683590208, valid = 0, 0 means intentally is set to zero\nAccuracy: Train =  65.74682683590208, valid = 0, 0 means intentally is set to zero\n"
    }
   ],
   "source": [
    "train_accuracy = train_aacuracy_fun(net)\n",
    "print(f\"Accuracy: Train =  {train_accuracy}, valid = {valid_accuracy}, 0 means intentally is set to zero\")\n",
    "# valid_accuracy = validation_aacuracy_fun(net)\n",
    "print(f\"Accuracy: Train =  {train_accuracy}, valid = {valid_accuracy}, 0 means intentally is set to zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ">> Target=47LIC3408, Output = ('47TI1713', (tensor([[[ 2.8783e-01,  1.6483e-01, -3.4231e-01,  7.4585e-02,  1.6151e-01,\n           4.0563e-03, -3.2046e-02,  1.4720e-02, -4.5031e-01, -5.3719e-01,\n          -9.9898e-02,  1.2104e-01,  9.2255e-01, -4.1955e-01, -1.0587e-01,\n           1.5443e-01,  1.6324e-01, -3.7993e-02,  3.1831e-02, -1.2007e-02,\n          -4.5332e-01,  7.7906e-01,  3.2840e-01, -4.2610e-01,  3.5148e-01,\n           6.2308e-01,  4.0928e-01,  2.0851e-03,  7.4351e-01,  5.6429e-01,\n           8.3267e-01, -4.4880e-01, -1.5362e-01, -3.1143e-01,  6.6036e-02,\n          -5.0778e-02, -1.9771e-01, -7.3669e-01,  5.4859e-02, -2.0804e-01,\n          -4.5646e-02,  1.8821e-01, -1.8868e-02,  2.7489e-02, -9.2930e-02,\n          -8.5812e-02, -2.1644e-02, -5.1700e-01, -2.1295e-01, -6.6207e-01,\n          -6.6450e-02, -1.7746e-02, -2.1170e-02, -1.8510e-01,  1.0439e-01,\n          -2.4383e-01,  3.9228e-01, -2.8720e-01,  4.0876e-03, -8.7549e-01,\n          -8.6007e-01,  1.9680e-02, -1.3628e-03, -1.9164e-01,  6.7035e-01,\n          -1.3976e-01,  4.5213e-01, -2.4405e-01, -3.7864e-01,  5.3192e-01,\n          -9.9129e-02,  6.6877e-01, -7.8151e-01,  2.4459e-01, -1.9178e-01,\n          -8.2517e-01,  3.2815e-01, -5.6677e-01,  1.0016e-01, -3.1887e-02,\n           9.3169e-03, -5.9324e-01,  2.2280e-01,  4.1072e-01,  2.7034e-01,\n           7.1930e-01,  6.4896e-02, -7.3981e-02, -1.1872e-01,  4.5997e-01,\n          -4.2485e-01, -3.2169e-01,  6.7594e-02, -7.1793e-01, -3.3559e-01,\n           7.5033e-01,  6.0039e-01, -1.9527e-04, -4.5859e-01, -1.0140e-01,\n           9.5267e-01, -2.0242e-01, -4.9304e-01, -2.7410e-01,  7.8831e-01,\n          -1.0801e-01,  4.2348e-01, -3.0967e-01, -1.7829e-01, -3.2027e-01,\n          -2.6298e-01, -9.5915e-03, -4.9041e-01,  2.2444e-01, -7.7302e-01,\n          -2.0309e-01, -2.2891e-01, -1.1942e-01,  1.2334e-03, -5.0574e-01,\n           1.8485e-01, -2.6450e-01,  1.0164e-01, -2.1156e-02,  5.5416e-02,\n          -6.4431e-01, -5.3117e-01, -8.0817e-02, -3.4383e-02,  5.7099e-01,\n           1.8659e-01,  5.7979e-01, -5.3137e-03,  5.3202e-01, -6.3724e-01,\n          -3.3051e-02,  1.1519e-01, -6.1081e-01,  4.5082e-01,  5.2655e-01,\n          -8.1292e-01, -1.0749e-01, -2.4668e-01,  1.1788e-01, -9.6842e-01,\n           5.0326e-02, -6.5340e-01,  3.1451e-01,  5.6457e-01, -7.9486e-02,\n           1.3952e-01,  3.3731e-02,  1.9937e-02,  2.1223e-01,  5.0842e-01,\n           4.5243e-01, -1.8081e-01,  6.0839e-02,  5.8391e-02,  1.7888e-01,\n           3.6108e-01, -3.7328e-01, -8.2634e-02, -5.7874e-03, -5.5767e-01,\n           3.4348e-02,  3.5938e-02,  3.2689e-01, -3.2404e-02,  4.8943e-03,\n          -3.2625e-01,  4.6522e-01,  2.8602e-01,  1.1138e-02, -1.9332e-01,\n          -2.4823e-01,  7.1709e-01,  8.6176e-03,  8.7453e-02,  4.5117e-01,\n           2.4498e-01, -1.0969e-01, -5.3987e-02, -7.7394e-01,  6.2371e-01,\n          -5.7885e-01,  4.4853e-01, -3.8163e-01, -8.1667e-02,  2.9289e-01,\n           3.2168e-01, -4.9831e-02,  7.0089e-01,  2.8657e-02,  2.4818e-02,\n           2.7238e-01,  5.2331e-01,  3.1626e-03, -1.7616e-01,  1.1841e-01,\n           5.5697e-01,  6.4672e-01, -1.6475e-01, -2.9705e-01, -6.8346e-01,\n           4.1176e-01, -6.7801e-01,  4.0531e-01,  2.6304e-02,  2.8691e-01,\n          -8.2955e-01,  7.8991e-02, -1.9766e-01,  2.9453e-01,  3.5108e-01,\n           2.2512e-02,  9.4532e-02, -3.5026e-01, -8.6575e-02, -1.3598e-02,\n           4.7926e-01, -3.0716e-01,  2.0468e-01,  9.8290e-02,  1.2834e-01,\n           3.3380e-01, -3.0395e-01, -2.2943e-01,  3.9471e-01, -3.0879e-02,\n           1.1025e-01,  8.3259e-03,  9.2932e-01, -1.7597e-01, -5.7993e-01,\n          -3.9085e-01,  1.6238e-01, -5.4084e-01, -2.9166e-01, -2.2921e-01,\n           6.7138e-01,  3.0681e-01,  2.8184e-01, -1.9381e-01,  1.0421e-02,\n          -3.7641e-01, -9.9051e-02,  4.7056e-01,  2.8193e-01,  5.9190e-01,\n          -7.2036e-01, -2.3205e-01,  2.8763e-01, -1.8778e-01, -5.1294e-01,\n          -4.3656e-01]],\n\n        [[-8.0474e-02, -1.0767e-02, -7.6075e-01,  1.5747e-02, -8.4606e-01,\n          -1.2121e-02, -5.6985e-02,  8.1761e-02, -3.3165e-02,  3.2639e-01,\n          -1.4803e-01,  4.3549e-02,  4.8235e-01, -3.0729e-04,  1.5517e-01,\n           6.1712e-01, -2.5853e-02, -4.5242e-01,  2.6055e-04, -9.6342e-01,\n           2.2657e-02,  3.7256e-01, -9.1098e-02,  9.6603e-01, -1.4689e-01,\n          -7.3731e-02, -5.0075e-01, -5.3372e-01,  9.5034e-03,  5.2834e-01,\n           2.7307e-02,  5.2409e-01,  1.0215e-01,  7.7108e-02, -3.1990e-02,\n          -1.1075e-01, -9.6977e-01,  8.2278e-02,  4.6870e-01, -1.5696e-01,\n           1.3329e-01, -2.1008e-01, -7.6680e-01,  5.2727e-01,  2.4066e-03,\n          -7.3929e-01, -5.7832e-01,  6.3118e-01, -1.9395e-01, -7.6050e-01,\n          -2.5950e-01, -6.0714e-01,  8.6343e-01,  1.7544e-01,  4.0651e-04,\n          -1.6213e-01, -8.8214e-01, -1.1346e-01, -3.5553e-03,  5.7283e-03,\n          -9.4970e-02,  7.6908e-01, -9.5013e-01,  7.8023e-01, -5.7235e-01,\n           5.6681e-01, -5.8971e-01, -1.3269e-02,  2.9448e-02,  1.3974e-01,\n          -3.7930e-01, -5.2489e-02, -1.1140e-01, -3.5629e-01,  7.9698e-03,\n           7.6973e-01, -7.1193e-02,  3.3623e-01, -6.5430e-01, -8.8923e-01,\n           3.5749e-01, -3.7911e-01,  5.9346e-01,  2.5215e-01, -7.5395e-01,\n          -2.6272e-01, -1.1108e-01, -9.9746e-01,  5.5403e-01,  8.2023e-02,\n           8.7653e-01,  7.3943e-01, -2.2237e-02, -9.0740e-02,  1.8677e-02,\n          -1.1456e-03, -1.2812e-01,  6.9348e-01,  5.8480e-01,  4.9961e-01,\n           8.3393e-01,  9.1586e-01,  1.5188e-01,  4.2394e-04,  6.8252e-01,\n           1.4727e-01,  2.5039e-01, -3.1515e-01,  2.6860e-01, -1.5556e-01,\n          -2.9851e-01,  4.0859e-01, -3.7264e-01,  6.8189e-01, -3.2147e-01,\n           8.3024e-02,  9.4350e-02, -7.8822e-01,  9.9885e-01, -9.4131e-01,\n           8.6446e-01, -5.1799e-01,  8.9162e-02,  3.1580e-05, -2.8733e-01,\n          -7.3944e-01,  2.7692e-04, -2.1357e-01,  1.5264e-01,  1.9767e-01,\n           8.6144e-01,  1.4547e-01,  1.7838e-03,  1.6408e-01,  1.2539e-02,\n           3.9162e-01, -1.2863e-01,  3.4918e-01, -1.8637e-01, -7.0191e-01,\n          -9.8280e-01,  1.6112e-02, -5.6200e-01, -2.1381e-01, -8.6756e-01,\n          -9.6836e-01,  8.0439e-01, -1.6399e-01, -6.2740e-01, -7.2253e-01,\n           1.8314e-01,  5.8855e-04,  1.6828e-01, -5.7099e-01,  7.5405e-03,\n          -5.0480e-01,  1.2949e-02, -2.1971e-01,  9.1128e-02, -2.3133e-01,\n           9.2982e-01,  2.8571e-01, -4.3089e-01, -3.3511e-02, -2.8473e-02,\n           9.7138e-01, -3.9011e-01, -9.5700e-03, -7.8511e-02,  7.8796e-01,\n           8.1775e-01,  6.5742e-01,  1.7353e-01,  7.4791e-01,  2.7711e-01,\n          -8.4442e-01,  2.8385e-02, -2.3532e-02, -7.9618e-03,  4.3612e-05,\n           4.5788e-01,  6.9815e-01,  1.6076e-02,  1.2849e-01,  4.5195e-01,\n          -1.2831e-01,  9.9503e-02, -2.7789e-01,  3.5525e-02,  6.0194e-01,\n           7.3282e-01, -8.6260e-01, -3.5252e-01,  9.7428e-02, -6.1356e-02,\n           3.2094e-02,  1.8490e-02, -9.7466e-01,  7.3775e-01,  6.7978e-01,\n          -7.5214e-01, -3.7764e-01,  3.2646e-02,  4.2050e-02, -6.1359e-03,\n           3.1492e-01, -8.3255e-01,  7.5938e-01, -1.5956e-01, -2.2577e-02,\n          -4.7810e-01, -7.0690e-01,  6.8549e-02, -9.7231e-01,  4.3786e-01,\n           9.3626e-01,  7.4689e-01, -2.2522e-03,  8.5270e-01,  8.6259e-01,\n           1.5229e-02, -8.2240e-01,  8.9468e-01, -5.5381e-01, -6.2299e-01,\n           7.4967e-01, -2.3799e-01,  9.5028e-01,  4.7364e-03,  4.9677e-02,\n          -8.9548e-03,  1.2575e-01,  1.0973e-02, -4.6615e-01, -9.5669e-01,\n           3.8690e-01, -6.1516e-01,  8.7616e-01,  5.0775e-01, -4.3276e-06,\n          -6.5337e-02,  7.1642e-01, -2.4305e-01, -5.0560e-02, -3.8731e-02,\n          -8.9668e-01,  6.1732e-01, -8.4628e-01, -6.5499e-01, -4.2129e-02,\n          -8.2241e-01, -5.4495e-01, -3.9239e-02,  4.4189e-01,  9.6122e-01,\n          -6.8128e-02]]], device='cuda:0', grad_fn=<CudnnRnnBackward>), tensor([[[ 9.1653e-01,  1.6636e-01, -3.7877e-01,  8.7481e-02,  1.6437e-01,\n           1.8048e-02, -9.2331e-02,  2.5131e-02, -6.8941e-01, -6.0619e-01,\n          -1.1322e-01,  1.4418e-01,  2.6453e+00, -4.4977e-01, -4.3060e-01,\n           4.3387e-01,  1.6628e-01, -3.9156e-02,  5.9343e-02, -1.2416e-02,\n          -5.1089e-01,  1.0751e+00,  5.9505e-01, -9.3027e-01,  9.8576e-01,\n           7.3234e-01,  4.5476e-01,  5.1899e-03,  1.1570e+00,  6.6442e-01,\n           1.6269e+00, -5.1858e-01, -1.8352e-01, -4.4372e-01,  5.6669e-01,\n          -1.0725e-01, -3.2861e-01, -2.3239e+00,  1.6336e-01, -2.2103e-01,\n          -4.6658e-02,  2.9706e+00, -6.0200e-01,  2.8825e-02, -8.8947e-01,\n          -8.8386e-02, -7.7084e-02, -5.8960e-01, -3.6086e-01, -1.2307e+00,\n          -1.6751e-01, -6.3940e-02, -6.4291e-01, -5.4133e-01,  1.0832e-01,\n          -1.0454e+00,  4.2167e-01, -1.2976e+00,  4.4892e-03, -1.4148e+00,\n          -1.5953e+00,  7.2639e-01, -2.7174e-02, -1.9482e-01,  8.5309e-01,\n          -1.4764e-01,  7.4540e-01, -2.4913e-01, -4.4631e-01,  7.7524e-01,\n          -1.3691e-01,  9.1711e-01, -1.1488e+00,  2.5178e-01, -1.9506e-01,\n          -1.2302e+00,  4.6556e-01, -6.4557e-01,  5.1533e-01, -3.2650e-02,\n           1.1699e-02, -7.1584e-01,  2.3639e-01,  6.4066e-01,  6.3270e-01,\n           9.1037e-01,  6.7678e-01, -8.3058e-02, -2.2787e+00,  8.0430e-01,\n          -4.5673e-01, -3.6858e-01,  1.0690e-01, -9.2077e-01, -3.6785e-01,\n           9.9912e-01,  7.2903e-01, -7.2170e-03, -5.1743e-01, -1.1500e-01,\n           1.8901e+00, -2.3857e-01, -5.4750e-01, -2.8424e-01,  1.0787e+00,\n          -4.4467e-01,  4.9551e-01, -3.2696e-01, -2.8837e-01, -1.2664e+00,\n          -2.7948e-01, -2.6442e-02, -1.6015e+00,  2.9546e-01, -1.0464e+00,\n          -3.1772e-01, -2.4554e-01, -1.4067e-01,  6.3082e-02, -7.8778e-01,\n           3.3957e-01, -2.9724e-01,  1.0727e-01, -8.6480e-01,  1.3072e+00,\n          -7.9994e-01, -6.3416e-01, -2.6763e-01, -2.8389e-01,  1.4663e+00,\n           2.4964e+00,  6.8891e-01, -1.3196e-02,  6.9721e-01, -8.2217e-01,\n          -3.3138e-02,  5.0974e-01, -7.9081e-01,  1.0903e+00,  9.1564e-01,\n          -1.1646e+00, -1.1895e-01, -3.7139e-01,  2.0592e-01, -2.1839e+00,\n           7.6785e-02, -7.8948e-01,  3.4058e-01,  6.4728e-01, -8.2040e-02,\n           7.1978e-01,  4.1480e-02,  5.1673e-01,  2.2370e-01,  5.6187e-01,\n           6.9683e-01, -7.1329e-01,  1.1209e-01,  1.0216e-01,  3.8048e-01,\n           4.0789e-01, -3.9483e-01, -9.2285e-02, -9.1621e-03, -6.4069e-01,\n           3.5297e-02,  1.4545e-01,  1.0040e+00, -3.8869e-02,  1.4036e-02,\n          -3.4559e-01,  5.5430e-01,  3.1556e-01,  9.0398e-01, -3.9603e-01,\n          -8.2331e-01,  1.9444e+00,  1.1371e-01,  2.1289e-01,  5.2436e-01,\n           9.3656e-01, -1.8321e-01, -5.4595e-02, -1.0784e+00,  7.3460e-01,\n          -6.6980e-01,  4.8289e-01, -4.6128e-01, -1.7910e+00,  9.2122e-01,\n           3.7875e-01, -5.2700e-02,  8.7066e-01,  2.8903e-02,  2.4952e-02,\n           5.4279e-01,  6.6030e-01,  7.2051e-03, -1.0300e+00,  1.2727e-01,\n           8.0236e-01,  1.1579e+00, -2.0650e-01, -6.0938e-01, -8.9386e-01,\n           5.3348e-01, -8.6351e-01,  4.3352e-01,  3.6795e-01,  3.1567e-01,\n          -1.5823e+00,  3.4357e-01, -9.5253e-01,  3.2148e-01,  6.9257e-01,\n           2.6028e-02,  6.1908e-01, -4.6553e-01, -1.2934e-01, -5.5017e-02,\n           5.2316e-01, -4.4247e-01,  3.6071e-01,  9.9002e-02,  1.4370e-01,\n           3.9873e-01, -6.1712e-01, -2.6967e-01,  1.0035e+00, -4.2622e-02,\n           6.4044e-01,  1.9977e-02,  1.9569e+00, -2.1896e-01, -6.7145e-01,\n          -4.6055e-01,  5.8448e-01, -1.8055e+00, -3.0708e-01, -2.5355e-01,\n           2.6166e+00,  3.3925e-01,  3.7463e-01, -1.8385e+00,  1.0608e-02,\n          -1.0828e+00, -1.3774e-01,  6.0946e-01,  9.7134e-01,  1.1523e+00,\n          -9.1856e-01, -2.9138e-01,  3.0074e-01, -2.1068e-01, -5.6925e-01,\n          -5.1711e-01]],\n\n        [[-8.0711e-02, -1.1693e-02, -3.4839e+00,  2.6505e-02, -1.7372e+00,\n          -1.6405e-02, -6.7158e+00,  1.8630e+00, -9.2245e-01,  7.5219e-01,\n          -3.1855e+00,  7.5924e-02,  6.1542e-01, -2.5101e-01,  3.2321e+00,\n           4.5671e+00, -4.0345e-02, -1.7587e+00,  3.3774e+00, -2.1569e+00,\n           6.5840e-02,  4.0266e-01, -1.7327e+00,  5.2116e+00, -1.4976e-01,\n          -5.7933e-01, -2.7194e+00, -6.4144e-01,  9.2583e-01,  5.8863e-01,\n           3.7384e-01,  6.4991e-01,  1.2809e-01,  5.9952e-01, -5.6811e-01,\n          -1.1163e-01, -2.1318e+00,  8.5186e-02,  3.0368e+00, -1.5864e-01,\n           1.4489e-01, -2.5739e-01, -1.1309e+00,  6.1241e-01,  4.5146e-01,\n          -9.6727e-01, -1.6220e+00,  9.3635e-01, -4.0373e+00, -2.3614e+00,\n          -3.7743e+00, -2.8079e+00,  1.3521e+00,  5.9610e+00,  4.0653e-04,\n          -1.6361e-01, -1.4449e+00, -1.1827e-01, -9.6884e-02,  6.9756e-03,\n          -9.8368e-02,  1.0182e+00, -2.5704e+00,  1.0471e+00, -2.0497e+00,\n           1.1959e+00, -4.9413e+00, -3.2892e+00,  1.2569e+00,  1.6457e+00,\n          -8.2833e-01, -9.1244e-01, -5.3228e+00, -3.7274e-01,  9.5400e-03,\n           1.6117e+00, -7.1372e-02,  2.7558e+00, -5.3192e+00, -1.6653e+00,\n           1.0339e+00, -4.1087e-01,  9.9668e-01,  3.5633e-01, -9.8881e-01,\n          -1.8821e+00, -3.2875e-01, -3.4861e+00,  6.8565e-01,  8.5098e-02,\n           1.3644e+00,  9.9739e-01, -2.7714e+00, -5.1436e+00,  2.6154e+00,\n          -5.1483e+00, -1.3618e-01,  1.2739e+00,  6.7025e-01,  4.9941e+00,\n           1.2009e+00,  1.6506e+00,  1.5309e-01,  2.0229e+00,  1.0744e+00,\n           4.5546e+00,  2.7353e-01, -4.6817e+00,  6.7055e-01, -1.8241e-01,\n          -4.9177e+00,  4.3405e-01, -3.9226e-01,  1.0339e+00, -1.2674e+00,\n           3.8238e+00,  1.4386e-01, -1.8655e+00,  3.7702e+00, -1.9982e+00,\n           1.3290e+00, -5.7359e-01,  9.1549e-01,  1.4205e-02, -2.9604e-01,\n          -9.5853e-01,  3.1799e-04, -1.0015e+00,  7.1121e+00,  1.1235e+00,\n           1.4960e+00,  1.4705e-01,  1.3586e-01,  1.9895e-01,  7.8429e-01,\n           2.1114e+00, -3.0617e+00,  4.9383e-01, -1.9225e-01, -8.7861e-01,\n          -3.7000e+00,  1.1275e+00, -6.9838e-01, -5.4959e+00, -2.2716e+00,\n          -2.2434e+00,  1.2674e+00, -1.6597e-01, -7.3723e-01, -1.0168e+00,\n           1.8876e-01,  1.7775e-01,  3.1742e+00, -1.2435e+00,  4.1888e-02,\n          -1.1220e+00,  2.9773e-02, -2.3309e-01,  9.2122e-02, -2.3456e+00,\n           1.7328e+00,  3.6696e+00, -4.8113e-01, -7.6332e-02, -5.7239e+00,\n           6.2664e+00, -6.7565e-01, -9.3779e-01, -7.8747e-02,  1.5418e+00,\n           1.1523e+00,  1.3922e+00,  1.7538e-01,  1.7155e+00,  3.9110e+00,\n          -1.2575e+00,  1.9451e+00, -2.4318e-02, -8.1121e-03,  8.3962e-01,\n           3.7229e+00,  8.7457e-01,  1.6399e-02,  3.9623e+00,  4.9358e-01,\n          -1.2907e-01,  9.2236e-01, -2.9523e-01,  8.4292e-01,  1.7661e+00,\n           9.6082e-01, -1.4463e+00, -5.2915e-01,  8.7108e-01, -3.4551e-01,\n           4.1526e+00,  5.1135e+00, -2.1872e+00,  4.8093e+00,  1.0580e+00,\n          -9.7864e-01, -5.2417e+00,  3.3051e-02,  8.9578e-01, -1.9169e+00,\n           3.3292e-01, -3.2495e+00,  3.8473e+00, -1.6675e-01, -3.8196e+00,\n          -5.2251e-01, -2.5077e+00,  4.4963e+00, -2.2898e+00,  1.7964e+00,\n           2.1740e+00,  9.9251e-01, -3.4476e+00,  2.4819e+00,  1.7621e+00,\n           2.6970e+00, -1.4014e+00,  1.4980e+00, -1.2774e+00, -7.3014e-01,\n           9.7827e-01, -2.4455e-01,  2.7431e+00,  3.2062e+00,  4.9863e-02,\n          -7.7861e-02,  7.1364e+00,  5.6464e+00, -3.6907e+00, -1.9206e+00,\n           5.1399e+00, -7.3390e-01,  1.3779e+00,  5.7764e-01, -1.4347e+00,\n          -1.0445e+00,  1.3880e+00, -2.6380e-01, -5.2179e-02, -3.0617e+00,\n          -1.5270e+00,  3.1673e+00, -2.2414e+00, -7.8447e-01, -4.2383e-02,\n          -2.0158e+00, -7.9904e-01, -3.8240e+00,  5.5349e-01,  5.2447e+00,\n          -3.6538e+00]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)))\n"
    }
   ],
   "source": [
    "hidden = net.init_hidden(1)\n",
    "prime= ['NoName', 'NoName', 'NoName']\n",
    "input_seq = ['19LI105A', '47TI931A', '48XL001-ANN', '19LI105A', '47TI931A']\n",
    "target = '47LIC3408'\n",
    "output =sample(net,hidden,input_sequence=input_seq, prime=prime, top_k=None)\n",
    "print(f\">> Target={target}, Output = {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# class AlarmRNN(nn.Module):\n",
    "    \n",
    "#     def __init__(self,vocab_size, output_size,embedding_dim=80, hidden_dim=256, n_layers=2, drop_prob=0.5, batch_size=50):\n",
    "#         super(AlarmRNN,self).__init__()\n",
    "\n",
    "#         self.output_size = output_size\n",
    "#         self.drop_prob = drop_prob\n",
    "#         self.n_layers = n_layers\n",
    "\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#         # self.lr = lr\n",
    "        \n",
    "#         # creating character dictionaries\n",
    "#         # self.chars = tokens # vocab\n",
    "#         # self.int2char = dict(enumerate(self.chars))\n",
    "#         # self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        \n",
    "#         ## TODO: define the layers of the model\n",
    "        \n",
    "#         self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "#         self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=self.hidden_dim, num_layers=self.n_layers,dropout=self.drop_prob, batch_first=True)\n",
    "        \n",
    "#         self.droput = nn.Dropout(p=self.drop_prob)\n",
    "#         self.fc = nn.Linear(in_features=self.hidden_dim, out_features=output_size) \n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, x, hidden):\n",
    "#         ''' Forward pass through the network. \n",
    "#             These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "                \n",
    "#         ## TODO: Get the outputs and the new hidden state from the lstm\n",
    "#         x = x.long()\n",
    "#         embeds = self.embedding(x)\n",
    "#         out, hidden = self.lstm(embeds,hidden)\n",
    "#         out = self.droput(out)\n",
    "#         # Contiguous variables: If you are stacking up multiple LSTM outputs, it may be necessary to use .contiguous() to reshape the output.\n",
    "#         out = out.contiguous().view(-1,self.hidden_dim)\n",
    "#         print(\">> out shape\", out.size())\n",
    "#         out = self.fc(out)\n",
    "#         print(\">> out shape before softmax\", out.size())\n",
    "#         out = self.softmax(out)\n",
    "#         print(\">> out shape after softmax\", out.size())\n",
    "#         # return the final output and the hidden state\n",
    "#         return out, hidden\n",
    "    \n",
    "    \n",
    "#     def init_hidden(self):\n",
    "#         ''' Initializes hidden state '''\n",
    "#         # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "#         # initialized to zero, for hidden state and cell state of LSTM\n",
    "        \n",
    "#         weight = next(self.parameters()).data\n",
    "        \n",
    "#         if (train_on_gpu):\n",
    "#             hidden = (weight.new(self.n_layers, self.batch_size, self.hidden_dim).zero_().cuda(),\n",
    "#                   weight.new(self.n_layers, self.batch_size, self.hidden_dim).zero_().cuda())\n",
    "#         else:\n",
    "#             hidden = (weight.new(self.n_layers, self.batch_size, self.hidden_dim).zero_(),\n",
    "#                       weight.new(self.n_layers, self.batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "#         return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bittuprascondad3f64d142d7848d8b5ff812324ef08eb",
   "display_name": "Python 3.8.3 64-bit ('tupras': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}